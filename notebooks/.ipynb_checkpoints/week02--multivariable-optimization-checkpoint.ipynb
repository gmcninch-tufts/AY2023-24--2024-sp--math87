{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [George McNinch](http://gmcninch.math.tufts.edu) Math 87 - Spring 2024\n",
    "\n",
    "# § Multi-variable Optimization"
   ],
   "id": "99ceb755-c9b5-4b26-a6cd-f4ee64f33a2e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with functions of several variables\n",
    "\n",
    "Consider a function $f(x,y)$ of two variables. You learned in Calculus 3\n",
    "(*vector calculus*) how to search for the points $(x,y)$ in the plane\n",
    "$ℝ²$ at which $f$ assumes its maximum and minimum value. Let’s briefly\n",
    "recap this story.\n",
    "\n",
    "Recall that for a function of a single variable, critical points are\n",
    "those points for which the tangent line is horizontal. In the single\n",
    "variable case, the criteria depends instead on the *tangent plane*.\n",
    "\n",
    "Recall that the surface defined by $z = f(x,y)$ can be *parameterized*\n",
    "by $\\mathbf{r}(x,y) = (x,y,f(x,y))$. So a **normal vector** to this\n",
    "surface at a point $P = (x_0,y_0,f(x_0,y_0))$ on the surface is given by\n",
    "the *cross product* $$\\left (\\dfrac{\\partial \\mathbf{r}}{\\partial\n",
    "x} \\times \\dfrac{\\partial \\mathbf{r}}{\\partial y}\\right)_P.$$\n",
    "\n",
    "Alternatively, consider $F(x,y,z) = z-f(x,y)$ so that the surface is\n",
    "defined by $F = 0$. Then the gradient $\\nabla F$ defines a normal vector\n",
    "at each point $P$, where $$(\\nabla F)_P = \\left(\\dfrac{\\partial\n",
    "F}{\\partial x} \\mathbf{i} + \\dfrac{\\partial F}{\\partial y}\n",
    "\\mathbf{j} + \\dfrac{\\partial F}{\\partial z} \\mathbf{k}\\right)_P$$.\n",
    "\n",
    "There is a nice discussion here: [**normal\n",
    "vector**](https://en.wikipedia.org/wiki/Normal_(geometry)). Both points\n",
    "of view can be useful, but here they lead to the same formula. At the\n",
    "point $P=(x_0,y_0,f(x_0,y_0))$ one has a normal to the surface defined\n",
    "by $z = f(x,y)$ given by $$\\mathbf{n}\\vert_P = \\left (\n",
    "\\mathbf{i} + \\dfrac{\\partial f}{\\partial x} \\mathbf{k} \\right )_P\n",
    "\\times \\left ( \\mathbf{j} + \\dfrac{\\partial f}{\\partial y} \\mathbf{k}\n",
    "\\right )_P = \\left ( \\mathbf{k} - \\dfrac{\\partial f}{\\partial x}\n",
    "\\mathbf{i} - \\dfrac{\\partial f}{\\partial y} \\mathbf{j} \\right )_P$$\n",
    "\n",
    "Now, the **tangent plane** at $P$ to the surface $z = f(x,y)$ is just\n",
    "the plane orthogonal to this normal vector $\\mathbf{n}_P$. Thus, the\n",
    "tangent plane at $P$ is horizontal – parallel to the $x,y$-plan – just\n",
    "in case this normal vector points in the $\\mathbf{k}$ direction –\n",
    "i.e. provided that $$(\\clubsuit) \\quad\n",
    "\\dfrac{\\partial{f}}{\\partial{x}} \\bigg\\vert_{(x_0,y_0)} = 0 \\quad\n",
    "\\text{and} \\quad \\dfrac{\\partial{f}}{\\partial{y}}\n",
    "\\bigg\\vert_{(x_0,y_0)} = 0$$\n",
    "\n",
    "Mimicking the one variable case, we say that the points $(x_0,y_0)$ for\n",
    "which the tangent plane to the surface $P=(x_0,y_0,f(x_0,y_0))$ is\n",
    "horizontal are the *critical points*.\n",
    "\n",
    "So we find the critical points by simultaneously solving the equations\n",
    "$(\\clubsuit)$.\n",
    "\n",
    "There is a *second derivative test* which gives information about the\n",
    "“max/min status” of these critical points.\n",
    "\n",
    "To use this test, consider the matrix of second partial derivatives\n",
    "\n",
    "$$M(x_0,y_0) = \\begin{matrix} \\dfrac{\\partial^2 f}{\\partial x^2} &\n",
    "\\dfrac{\\partial^2 f}{\\partial x \\partial y} \\\\ \\dfrac{\\partial^2\n",
    "f}{\\partial y \\partial x} & \\dfrac{\\partial^2 f}{\\partial y^2} \\\\\n",
    "\\end{pmatrix} \\Bigg\\vert_{(x_0,y_0)}.$$\n",
    "\n",
    "For reasonable functions, the “mixed partials”\n",
    "$\\dfrac{\\partial^2 f}{\\partial x \\partial y}$ and\n",
    "$\\dfrac{\\partial^2 f}{\\partial y \\partial x}$ coincide.\n",
    "\n",
    "Remember that the determinant of a $2 \\times 2$ matrix\n",
    "$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ is $ad - bc$.\n",
    "\n",
    "So, the *determinant* of $M$ is the expression\n",
    "\n",
    "$$D=D(x_0,y_0) = \\left(\\dfrac{\\partial^2 f}{\\partial\n",
    "  x^2}\\cdot\\dfrac{\\partial^2 f}{\\partial y^2} -\n",
    "  \\left[\\dfrac{\\partial^2 f}{\\partial x \\partial y}\\right]^2\\right)\n",
    "  \\bigg\\vert_{(x_0,y_0)} $$\n",
    "\n",
    "Suppose that $(x_0,y_0)$ is a critical point. - If $D>0$ and\n",
    "$\\dfrac{\\partial^2 f}{\\partial  x^2}\\bigg\\vert_{(x_0,y_0)}<0$, then\n",
    "$f(x,y)$ has a relative maximum at $(x_0,y_0)$. - If $D>0$ and\n",
    "$\\dfrac{\\partial^2 f}{\\partial  x^2}\\bigg\\vert_{(x_0,y_0)}>0$, then\n",
    "$f(x,y)$ has a relative minimum at $(x_0,y_0)$.\n",
    "\n",
    "-   If $D<0$, then $f(x,y)$ has a saddle point at $(x_0,y_0)$.\n",
    "-   If $D=0$, the second derivative test is inconclusive."
   ],
   "id": "f240e74b-409d-45e0-aa6c-50ba4ff225c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html\n",
    "# https://matplotlib.org/3.3.1/gallery/mplot3d/surface3d.html\n",
    "\n",
    "def draw_graph(f,x,y,x0,y0,elev_azim=[]):\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    for idx,(e,a) in enumerate(elev_azim,start=1):\n",
    "        \n",
    "        ax = fig.add_subplot(1,len(elev_azim),idx,projection='3d',elev=e,azim=a)\n",
    "        ax.plot_wireframe(X,Y,f(X,Y))\n",
    "\n",
    "        ax.plot(x,y0*np.ones(y.shape), zs= f(x,y0), color=\"red\", linewidth=3)\n",
    "        ax.plot(x0*np.ones(x.shape),y, zs= f(x0,y), color=\"red\", linewidth=3)\n",
    "    \n",
    "    return fig\n"
   ],
   "id": "dfd18e12-ab87-48c2-aad9-aa3df23ee18c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "af=draw_graph(f,\n",
    "              x=np.linspace(-1,1,25),\n",
    "              y=np.linspace(-1,1,25),\n",
    "              x0=0,\n",
    "              y0=0,\n",
    "              elev_azim=[(35,15),(35,30),(35,75)])"
   ],
   "id": "1af391e5-84cf-4002-ab77-ded617a49075"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example:** Television manufacturer\n",
    "\n",
    "A company that makes TV sets sells two models: a 19” set and a 21” set.\n",
    "\n",
    "Their annual production costs are \\\\\\$ 195 per TV for the 19” model and\n",
    "\\\\\\$ 225 per TV for the 21” model, plus \\\\\\$ 400,000 per year in fixed\n",
    "costs.\n",
    "\n",
    "They expect to sell their production to a single wholesaler who will pay\n",
    "a base price of \\\\\\$ 339 per 19” TV and \\$399 per 21” TV. The wholesaler\n",
    "recieves a volume discount calculated as 1¢ per 19” TV + 0.3¢ per 21” TV\n",
    "for the 19” models and 1¢ per 21” TV + 0.4¢ per 19” TV for the 21”\n",
    "models.\n",
    "\n",
    "How many 19” and 21” TVs should be produced to maximize the profits?"
   ],
   "id": "d7c7b02d-86ed-4427-b5c7-d542101925fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through our modeling procedure. Let’s set up the problem and\n",
    "ask the right questions. What are our variables? - $s$ = \\# of 19” TVs\n",
    "produced - $t$ = \\# of 21” TVs produced - $p$ = selling price of each\n",
    "19” TV - $q$ = selling price of each 21” TV - $C$ = cost of production -\n",
    "$R$ = total revenue of sales - $P$ = total profit\n",
    "\n",
    "What do we *know* to start with??\n",
    "\n",
    "-   $p(s,t) = 339 − 0.01s − 0.003t$ dollars\n",
    "\n",
    "-   $q(s,t) = 399 − 0.004s − 0.01t$ dollars\n",
    "\n",
    "-   $R(s,t) = ps + qt = 339s − 0.01s^2 − 0.003st + 399t − 0.004st − 0.01t^2$\n",
    "\n",
    "    $= 339s + 399t − 0.01s^2 − 0.01t^2 − 0.007st \\quad \\text{dollars}$\n",
    "\n",
    "-   $C(s,t) = 400, 000 + 195s + 225t$ dollars\n",
    "\n",
    "-   $P(s,t) = R(s,t) - C(s,t)$\n",
    "\n",
    "    $= −400, 000 + 144s + 174t − 0.01s^2 − 0.01t^2 − 0.007st$ dollars\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Of course, our goal is to maximize profit – i.e. to find $(s_0,t_0)$ for\n",
    "which $P(s_0,t_0)$ is at a maximum.\n",
    "\n",
    "According to the discussion above, we should compute the partial\n",
    "derivitives of $P$ and simultaneously solve the equations $$0 =\n",
    "  \\dfrac{\\partial P}{\\partial s} = \\dfrac{\\partial P}{\\partial t}$$\n",
    "\n",
    "So we need to solve the equations:\n",
    "\n",
    "$$\\dfrac{\\partial P}{\\partial s} = 144 − 0.02s − 0.007t = 0$$\n",
    "\n",
    "$$\\dfrac{\\partial P}{\\partial t} = 174 − 0.02t − 0.007s = 0$$\n",
    "\n",
    "This amounts to solving the matrix equation\n",
    "\n",
    "$$\\begin{bmatrix} 0.02 & 0.007 \\\\ 0.007 & 0.02 \\end{bmatrix} \\begin{bmatrix} s \\\\ t \\end{bmatrix}\n",
    "    = \\begin{bmatrix} 144 \\\\ 174 \\end{bmatrix}$$\n",
    "\n",
    "which we can solve using *row reduction* on the corresponding augmented\n",
    "matrix:\n",
    "\n",
    "$$\\left[\\begin{array}{rr|r} 0.02 & 0.007 & 144 \\\\\n",
    "                   0.007 & 0.02 & 174 \\end{array} \\right]\n",
    "    \\sim \\left[\\begin{array}{rr|r} 1 & .35 & 7200 \\\\\n",
    "                   1 & 2.857 & 24857.14 \\end{array} \\right]\n",
    "    \\sim \\left[\\begin{array}{rr|r} 1 & .35 & 7200 \\\\\n",
    "                   0 & 2.507 & 17657.14 \\end{array} \\right]\n",
    "    \\sim \\left[\\begin{array}{rr|r} 1 & .35 & 7200 \\\\\n",
    "                   0 & 1 & 7043.135 \\end{array} \\right]\n",
    "        \\sim \\left[\\begin{array}{rr|r} 1 & 0 & 4734.9 \\\\\n",
    "                   0 & 1 & 7043.135 \\end{array} \\right]$$\n",
    "\n",
    "We find that the function $P$ has exactly one critical point which\n",
    "occurs at $(s_0,t_0) = (4735,7043)$.\n",
    "\n",
    "Let’s quickly pause and see how to solve this matrix equation using the\n",
    "computer:"
   ],
   "id": "8c70fdc1-84dd-49ff-9e41-649c4aaae463"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= np.array([[.02,.007],[.007,.02]])\n",
    "b=np.array([144,174])\n",
    "np.linalg.solve(A,b)"
   ],
   "id": "1da8a617-f915-482a-a1d5-a5d3ff29cc8e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix of second derivatives is\n",
    "$$ \\begin{bmatrix} \\dfrac{\\partial^2 P}{\\partial s^2} &\n",
    " \\dfrac{\\partial^2 P}{\\partial s \\partial t} \\\\ \\dfrac{\\partial^2\n",
    " P}{\\partial s^2} & \\dfrac{\\partial^2 P}{\\partial s \\partial t}\n",
    " \\end{bmatrix} = \\begin{bmatrix} -0.02 & -0.007 \\\\ -0.007 & -0.02\n",
    " \\end{bmatrix}$$ which has determinant $(0.02)^2 - (.007)^2 > 0$.\n",
    "\n",
    "Since $\\dfrac{\\partial^2 P}{\\partial s^2} = -0.02 < 0$, the second\n",
    "derivative test shows that $P$ has is local maximum at $(s_0,t_0)$, and\n",
    "we conclude that profit is maximized there.\n",
    "\n",
    "(Technically, we should check for minima “on the boundary” but in this\n",
    "case that would be the point $(0,0)$ which clearly doesn’t maximize\n",
    "$P$).\n",
    "\n",
    "Let’s produce a (or a few…) graph(s) to confirm our work:"
   ],
   "id": "672deea6-8c8a-4149-a6f3-ca6734df3571"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = np.linspace(2000,8000,25)\n",
    "t = np.linspace(2000,8000,25)\n",
    "\n",
    "\n",
    "def p(s,t):\n",
    "    return -400000 + 144*s + 174*t - 0.01*s**2 - 0.01*t**2 - .007*s*t\n",
    "\n",
    "a=draw_graph(p,\n",
    "             x=s,\n",
    "             y=t,\n",
    "             x0=4735,\n",
    "             y0=7043,\n",
    "             elev_azim=[(45,20),(45,55)])\n",
    "\n"
   ],
   "id": "b572b50c-216f-49f5-8630-229dec802399"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countour plot\n",
    "\n",
    "S,T = np.meshgrid(s,t)\n",
    "\n",
    "figc = plt.figure(figsize=(20,10))\n",
    "axc = figc.add_subplot()\n",
    "axc.contourf(S,T,p(S,T),levels=20\n",
    "             , extend='both')\n",
    "axc.scatter(4735,7043,marker=\"X\")"
   ],
   "id": "e3a44335-ea18-46a6-826b-5449ea7a1ba4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.cell} \\# Sensitivity Analysis (the television example, continued)\n",
    "\n",
    "Just as in the single-variable case, we should be able to perform\n",
    "*Sensitivity Analysis* for our optimization problems.\n",
    "\n",
    "Let’s start by picking a parameter we want to change.\n",
    "\n",
    "**Definition**(Price Elasticity). Let the *Price Elasticity* parameter,\n",
    "$a$, be the amount the selling price of say the 19” TVs decreases per\n",
    "19” TV sold.\n",
    "\n",
    "We started with $a = 0.01$.\n",
    "\n",
    "Using this let’s rewrite the Profit equation with $a$:\n",
    "\n",
    "$$P(s,t) = 144s + 174t − as^2 − 0.01t^2 − 0.007st − 400000$$\n",
    "\n",
    "We now look for optimal values $s = s(a)$ and $t = t(a)$ depending on\n",
    "$a$.\n",
    "\n",
    "We need to solve the system: $$\\left\\{\\begin{matrix}\n",
    "    0 & = \\dfrac{\\partial P}{\\partial s} = 144 -2as - 0.007t \\\\\n",
    "    0 & = \\dfrac{\\partial P}{\\partial t}= 174 -.02t - 0.007s\n",
    "  \\end{matrix}\\right .$$\n",
    "\n",
    "Solving this system, find that $s = s(a) = \\dfrac{144-0.007t}{2a}$ so\n",
    "that $$174 - 0.02t - 0.007\\cdot \\dfrac{144-0.007t}{2a} = 0$$ We now find\n",
    "that $$t = 8,700 - \\dfrac{581,700}{40,000a -49}$$ and $$s =\n",
    "\\dfrac{1,662,000}{40,000a-49}$$\n",
    "\n",
    "Now we check the sensitivity:\n",
    "\n",
    "$$S(s,a) = \\dfrac{ds}{da} \\cdot \\dfrac{a}{s} \\quad \\text{and} \\quad\n",
    "S(t,a) = \\dfrac{dt}{da} \\cdot \\dfrac{a}{t}$$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$S(s,a) = \\dfrac{66,480,000,000}{(40,000a - 49)^2} \\cdot\n",
    "            \\dfrac{40,000a^2 - 49a}{1,662,000}$$ and $$S(t,a) =\n",
    "            \\dfrac{23,268,000,000}{(40,000a - 40)^2} \\cdot\n",
    "            \\dfrac{40,000a^2 - 49a}{8,700 \\cdot (40,000a - 49) -\n",
    "            581,700}$$\n",
    "\n",
    "The sensitivity near our guess of $a = 0.01$ is thus\n",
    "\n",
    "$$S(s,0.01) \\approx -1.1 \\quad \\text{and} \\quad S(t,0,01) \\approx\n",
    "  0.2$$\n",
    "\n",
    "**Interpretation:** If the price elasticity increases by 10% (i.e. the\n",
    "warehouse receives a bigger bulk discount) the optimal value of $s$\n",
    "decreases by 11% and the optimal value of $t$ increases by 2.7%"
   ],
   "id": "9950c2c9-0388-4916-825d-ca16e9071018"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.2",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": "2"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 }
}
